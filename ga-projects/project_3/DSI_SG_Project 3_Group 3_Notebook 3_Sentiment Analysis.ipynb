{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Project 3: Web APIs & NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "*Group 3* | *Team Members: Constance, Wenzhe, Matthew, Joel*\n",
    "\n",
    "### <b> Notebook 3: Sentiment Analysis using VADER </b>\n",
    "\n",
    "<b> (a) Overview of Notebook 3 </b>\n",
    "\n",
    "In this notebook, we will make use of the SentimentIntensityAnalyzer for sentiment analysis from our 2 selected subreddits.\n",
    "\n",
    "The rationale is that we want to preserve the original sentiments of the comments and if preprocessing were to be done on them i.e. stemming the words, the original sentiments will be lost. Based on background research, the VADER lexicon is robust enough to interpret text \"as-is\", hence we will put in the comments directly.\n",
    "\n",
    "<br>\n",
    "\n",
    "<b> (b) Structure of Notebook 3 </b>\n",
    "* Use SentimentIntensityAnalyzer for Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Import Libraries & Read Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sentiment analysis import\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read filtered cleaned coffee and tea datasets ()\n",
    "df_coffee = pd.read_csv(\"data/coffee_comments_clean_merged_filtered.csv\")\n",
    "df_tea    = pd.read_csv(\"data/tea_comments_clean_merged_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>author_name</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>post_hint</th>\n",
       "      <th>self_text</th>\n",
       "      <th>author_name_thread</th>\n",
       "      <th>url</th>\n",
       "      <th>url_is_media</th>\n",
       "      <th>comment_score_top_or_bottom_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19agk2c</td>\n",
       "      <td>kikp8lv</td>\n",
       "      <td>Hi! I’m a morning coffee drinker but I never m...</td>\n",
       "      <td>2</td>\n",
       "      <td>testingpage2025</td>\n",
       "      <td>19agk2c</td>\n",
       "      <td>[MOD] The Daily Question Thread</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\nWelcome to the daily [/r/Coffee](https://...</td>\n",
       "      <td>menschmaschine5</td>\n",
       "      <td>https://www.reddit.com/r/Coffee/comments/19agk...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19agk2c</td>\n",
       "      <td>kikxhmz</td>\n",
       "      <td>Any Scooters employees around? I need to know ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Ok_Bet_2634</td>\n",
       "      <td>19agk2c</td>\n",
       "      <td>[MOD] The Daily Question Thread</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\nWelcome to the daily [/r/Coffee](https://...</td>\n",
       "      <td>menschmaschine5</td>\n",
       "      <td>https://www.reddit.com/r/Coffee/comments/19agk...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19agk2c</td>\n",
       "      <td>kil6vl0</td>\n",
       "      <td>I can't find a pumpkin spice latte recipe that...</td>\n",
       "      <td>1</td>\n",
       "      <td>automirage04</td>\n",
       "      <td>19agk2c</td>\n",
       "      <td>[MOD] The Daily Question Thread</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\nWelcome to the daily [/r/Coffee](https://...</td>\n",
       "      <td>menschmaschine5</td>\n",
       "      <td>https://www.reddit.com/r/Coffee/comments/19agk...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19agk2c</td>\n",
       "      <td>kilaorz</td>\n",
       "      <td>Hey all! I live in Costa Rica and regularly bu...</td>\n",
       "      <td>1</td>\n",
       "      <td>chuvakinfinity</td>\n",
       "      <td>19agk2c</td>\n",
       "      <td>[MOD] The Daily Question Thread</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\nWelcome to the daily [/r/Coffee](https://...</td>\n",
       "      <td>menschmaschine5</td>\n",
       "      <td>https://www.reddit.com/r/Coffee/comments/19agk...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19agk2c</td>\n",
       "      <td>kilrgdc</td>\n",
       "      <td>Hi everyone! Any recommendations for pour over...</td>\n",
       "      <td>1</td>\n",
       "      <td>exposinglikeshane</td>\n",
       "      <td>19agk2c</td>\n",
       "      <td>[MOD] The Daily Question Thread</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\nWelcome to the daily [/r/Coffee](https://...</td>\n",
       "      <td>menschmaschine5</td>\n",
       "      <td>https://www.reddit.com/r/Coffee/comments/19agk...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  thread_id comment_id                                       comment_text  \\\n",
       "0   19agk2c    kikp8lv  Hi! I’m a morning coffee drinker but I never m...   \n",
       "1   19agk2c    kikxhmz  Any Scooters employees around? I need to know ...   \n",
       "2   19agk2c    kil6vl0  I can't find a pumpkin spice latte recipe that...   \n",
       "3   19agk2c    kilaorz  Hey all! I live in Costa Rica and regularly bu...   \n",
       "4   19agk2c    kilrgdc  Hi everyone! Any recommendations for pour over...   \n",
       "\n",
       "   comment_score        author_name       id                            title  \\\n",
       "0              2    testingpage2025  19agk2c  [MOD] The Daily Question Thread   \n",
       "1              2        Ok_Bet_2634  19agk2c  [MOD] The Daily Question Thread   \n",
       "2              1       automirage04  19agk2c  [MOD] The Daily Question Thread   \n",
       "3              1     chuvakinfinity  19agk2c  [MOD] The Daily Question Thread   \n",
       "4              1  exposinglikeshane  19agk2c  [MOD] The Daily Question Thread   \n",
       "\n",
       "   score  num_comments post_hint  \\\n",
       "0      2            58       NaN   \n",
       "1      2            58       NaN   \n",
       "2      2            58       NaN   \n",
       "3      2            58       NaN   \n",
       "4      2            58       NaN   \n",
       "\n",
       "                                           self_text author_name_thread  \\\n",
       "0   \\n\\nWelcome to the daily [/r/Coffee](https://...    menschmaschine5   \n",
       "1   \\n\\nWelcome to the daily [/r/Coffee](https://...    menschmaschine5   \n",
       "2   \\n\\nWelcome to the daily [/r/Coffee](https://...    menschmaschine5   \n",
       "3   \\n\\nWelcome to the daily [/r/Coffee](https://...    menschmaschine5   \n",
       "4   \\n\\nWelcome to the daily [/r/Coffee](https://...    menschmaschine5   \n",
       "\n",
       "                                                 url  url_is_media  \\\n",
       "0  https://www.reddit.com/r/Coffee/comments/19agk...             0   \n",
       "1  https://www.reddit.com/r/Coffee/comments/19agk...             0   \n",
       "2  https://www.reddit.com/r/Coffee/comments/19agk...             0   \n",
       "3  https://www.reddit.com/r/Coffee/comments/19agk...             0   \n",
       "4  https://www.reddit.com/r/Coffee/comments/19agk...             0   \n",
       "\n",
       "   comment_score_top_or_bottom_4  \n",
       "0                              1  \n",
       "1                              1  \n",
       "2                              1  \n",
       "3                              1  \n",
       "4                              1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coffee.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Using VADER to derive sentiment analysis for coffee and tea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate Sentiment Intensity Analyzer\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> (a) Defining a sentiment score calculation function </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to anaylze sentiment score for each row in subset df and return the overall average sentiment score for the entire df\n",
    "from statistics import mean \n",
    "\n",
    "def sentiment_score(df, column):\n",
    "    neg_score = []\n",
    "    neu_score = []\n",
    "    pos_score = []\n",
    "    comp_score = []\n",
    "\n",
    "    for row in df[column]:\n",
    "        score = sentiment_analyzer.polarity_scores(str(row)) # for every row, it will come out as a dictionary result of {'neg': value, 'neu': value , 'pos': value, 'compound': value}\n",
    "        \n",
    "        # append each row's score into the respective component\n",
    "        neg_score.append(score[\"neg\"]) \n",
    "        neu_score.append(score[\"neu\"])\n",
    "        pos_score.append(score[\"pos\"])\n",
    "        comp_score.append(score[\"compound\"])\n",
    "\n",
    "        # calculate the overall average score for each component and return it \n",
    "        average_score = [f\"neg score: {mean(neg_score)}, neu score: {mean(neu_score)}, pos score: {mean(pos_score)}, compound score: {mean(comp_score)}\"]\n",
    "    return average_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> (b) Invoke the function on the subreddits </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg score: 0.03949098532494759, neu score: 0.7836641509433963, pos score: 0.1753754716981132, compound score: 0.3475005031446541']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke function on df_tea\n",
    "sentiment_score(df_tea, \"comment_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg score: 0.0417536170212766, neu score: 0.8315363829787235, pos score: 0.1265008510638298, compound score: 0.3626987234042553']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke function on df_coffee_subs\n",
    "sentiment_score(df_coffee, \"comment_text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:\n",
    "\n",
    "The sentiment analysis for each group and the scores are as follows:\n",
    "\n",
    "Type| Negative score| Neutral score| Positive score| Compound score|\n",
    "|---|---|---|---|---|\n",
    "|Tea|0.040|0.784|0.176|0.348|\n",
    "|Coffee|0.042|0.832|0.127|0.363|\n",
    "\n",
    "Based on the results, we can deduce the following:\n",
    "* coffee drinkers are highly neutral in their language - more neutral sentiments generated\n",
    "* tea drinkers tend to produce more positive sentiment-inducing comments compared to coffee drinkers\n",
    "* considering that compound score is computed based on the negative, neutral and positive scores and normalizing the sum, it could possibly be that the strong neutral score of coffee drinkers resulted in an overall higher compound score than tea drinkers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doodlesvivo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
